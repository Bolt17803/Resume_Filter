{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12125cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langsmith_api_key - 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\n",
    "\n",
    "#GOOGLE_API_KEY - AIzaSyAK98AyVqJ61lEQJSVxFHvjXWKeCdzB2mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c84ffade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGSMITH_TRACING'] = \"true\"\n",
    "os.environ['LANGSMITH_API_KEY'] = \"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\"\n",
    "os.environ['LANGSMITH_PROJECT'] = \"default\"\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = \"AIzaSyAK98AyVqJ61lEQJSVxFHvjXWKeCdzB2mc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60110edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "model = init_chat_model(\"gemini-2.5-flash\", model_provider=\"google_genai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be445c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao!', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': []}, id='run--849f237c-76c0-4fb8-9dc0-85fafa3786b4-0', usage_metadata={'input_tokens': 10, 'output_tokens': 36, 'total_tokens': 46, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 34}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33d7b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"\"\"\n",
    "You are an AI assistant that extracts professional information from text.\n",
    "Given resume text, identify and list:\n",
    "\n",
    "1. Skills — both technical and soft skills.\n",
    "2. Experience — summarised job titles, company names, Education Qualification and durations.\n",
    "\n",
    "Return the output in the following exact format:\n",
    "\n",
    "Skills:\n",
    "- Skill 1\n",
    "- Skill 2\n",
    "- Skill 3\n",
    "\n",
    "Experience:\n",
    "- Job Title at Company Name (Start - End)\n",
    "- Job Title at Company Name (Start - End)\n",
    "\n",
    "Only include information explicitly stated in the text.\n",
    "Do not infer or fabricate details.\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2be65222",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../uploads/session-1/RESUME.txt\", \"r\") as file:\n",
    "    resume_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd6e9b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='\\nYou are an AI assistant that extracts professional information from text.\\nGiven resume text, identify and list:\\n\\n1. Skills — both technical and soft skills.\\n2. Experience — summarised job titles, company names, Education Qualification and durations.\\n\\nReturn the output in the following exact format:\\n\\nSkills:\\n- Skill 1\\n- Skill 2\\n- Skill 3\\n\\nExperience:\\n- Job Title at Company Name (Start - End)\\n- Job Title at Company Name (Start - End)\\n\\nOnly include information explicitly stated in the text.\\nDo not infer or fabricate details.\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='Anumula Chaitanya Sai +91-8639627774\\nBachelor of Technology anumulacs@iitbhilai.ac.in\\nin Computer Science and Engineering GitHub\\nIndian Institute of Technology, Bhilai LinkedIn\\nEducation\\nYear Degree/Certificate Institute CGPA/Percentage\\n2021-2025 B.Tech Computer Science Engineering IIT Bhilai 8.95\\n2019-2021 TSBIE(XI-XII) Narayana Junior College 94%\\n2018 CBSE(X) Delhi Public School, Nacharam 96%\\nINTERNSHIPS\\n•Edge Lab @ IIT KHARAGPUR May 2024 - August 2024\\nFederated Learning Researcher IIT KHARAGPUR\\n–Create a versatile framework for simulating asynchronous and synchronous Federated Learning Simulations using Ray, and\\nworked on developing an algorithm to redress the client failure situation for achieving global model convergence. Working\\non intelligent aggregation strategy for creating a robust global model in presence of clients data heterogeneity.\\nThis work is done under Dr.Subhajit Sidhantha\\n•IBITF @ IIT BHILAI January 2025 - present\\nMachine Learning Intern IIT BHILAI\\n–Improving the financial condition of farmers through real-time precision agriculture: plant disease detection. Working on\\ndata collection and pre-processing of images captured via drone. This work is done under the guidance of Dr.Soumajit\\nPramanik\\nResearch Experience\\n•S3 Lab November 2023 - present\\nSplit Learning Researcher IIT BHILAI\\n–Solved the issue of degradation in ML model performance during test time shifts(OOD) and high resource consumption for\\ndeployment on edge devices, by leveraging a split architecture with activation caching and an adaptive test-time inferencing.\\nOur approach consistently achieves a 96 ×reduction in computation cost for image classification and a 4.5 ×reduction in\\ncommunication traffic compared to state-of-the-art baselines with a 29% improvement of accuracy on average in OOD test\\nsamples. This work is done under the supervision of Dr.Gagan Raj Gupta\\n–The Split Learning framework is further deployed in Jetson Orin Nano using grpc for real-life deployment on edge systems,\\nwhich can benefit from the Split Framework. Code is available here:- Github\\nProjects\\n•Crop-Health-Monitor May 2023 - July 2023\\nproject under professor Github\\n–Developed and trained Deep Learning models to predict disease using leaf image, complemented by the creation of a website\\nusing ReactJS and an Android application using Flutter. Utilized Google Cloud services, including hosting the backend\\nserver on a Google Cloud VM, utilizing Google Cloud Storage for storing the Neural Network model, and deploying the\\nwebsite on Google App Engine. Implemented the use of the SAM model for leaf segmentation in the neural network, which\\naccepts segmented images as input Technologies & Algo Used: CNN’s, image processing techniques, Cloud Computing,\\nReactJS, HTML, CSS, Flutter, FastAPI, Pytorch, numpy\\n•RL_Spec_Ops October 2023 - November 2023\\nAI Major Project Github\\n–Engineered a custom environment using Petting Zoo and RLLib (Ray) libraries, incorporating 2D visual graphics with\\npygame to train a multi-agent system via Reinforcement Learning. The project simulates a special operation scenario,\\nwhere SEALs and terrorists strategically optimize rewards by eliminating opponents and protecting themselves from attacks.\\nAgents are tested in an unfamiliar setting. Custom reward functions were crafted to enable diverse policy learning for SEALs\\nand terrorists Technologies & Algo Used: RL(PPO,DQN), ray tracing, Ray, Pytorch, numpy, PyGame\\n•Multimodal Fusion of Text and Image Data for Object localization November 2024 - December 2024\\nNLP Major Project Github\\n–Isn’t it awesome if the machine can identify the objects in the image using text? This is precisely what the project aims for!\\nAn encoder-decoder model is trained to generate the mask highlighting the region containing the objects specified in the\\ntext. The cross-attention between the text and image modalities has helped create a representation localizing the object,\\nand the decoder is trained to create the mask from the encoding. Magic Brush Dataset is used for training, and custom\\nencoder-decoder architecture is used. Technologies & Algo Used: Multi-modal alignment, Attention, NLP, CV, Pytorch,\\nnumpy•Text to Virtual Try On November 2024 - November 2024\\nDeep Learning for Computer Vision Major project Github\\n–What if someone wants to try wearing clothes they can describe in words? The project creates a pipeline from the description\\nof the clothing to virtually showing how a person looks when they wear it. They can also visualize the fit of the clothing\\nto see how it looks in loose and tight fittings. The task is achieved by generating clothing from text descriptions via\\ndiffusion and inpainting of generated apparel on a cloth-agnostic picture of humans using zero-shot cross attention on a pre-\\ntrained diffusion-based inpainting model. Morphological processing of dense pose is done to support the fitting simulation.\\nTechnologies & Algo Used: Text-to-Image Transformer, Virtual-Try-On, NLP, Image Processing, Pytorch, numpy\\n•Automating Text Recognition and Transliteration of Historical Documents Febuary 2024 - March 2024\\nPersonal Project Github\\n–Prepared my own Dataset from the early modern printed Spanish texts of the seventeenth century for doing the text\\nrecognition task, the collected processed data can be viewed here, text recognition is being done using the Convolutional\\nRecurrent Neural Network architecture and achieved an accuracy of 95% on the test dataset Technologies & Algo Used:\\nCRNN’s, Text-Reognition, Object Detection, Pytorch, numpy\\n•Drone Height Estimation via Camera Imaging Jan 2023 - Febuary 2023\\nPersonal project\\n–Applied the OpenCV library for Aruco marker detection on the drone, did camera calibration for precise estimation of\\nthe camera pose in relation to the drone. Implemented methodologies to derive real-world coordinates and determine the\\ndrone’s height, utilizing a ceiling-mounted camera. Technologies & Algo Used: Aruco detection, Camera calibration, Depth\\nestimation\\n•Open Lake Website July 2023\\nHackathon Github\\n–Created the website for OpenLake(the open source community of IIT BHILAI) using ReactJS, Figma and hosted using\\nvercel.Technologies & Algo Used: ReactJS, HTML, CSS\\nTechnical Skills\\n•Programming Languages :Python, JavaScript\\n•Tools and Frameworks :Git, Github, Docker, Tensorflow, Pytorch, Langchain, Crew AI, SQL, ReactJS, Flutter, NNI, Google\\nCloud Computing, AWS, FastAPI, Jupyter, Visual Studio & Figma\\n•Skills:Machine Learning, Computer Vision, Data Science, Deep Learning, Reinforcement Learning & Federated Learning\\n•Operating Systems :Windows, Linux & Android\\nKey courses taken\\n•CSE & Maths :Discrete Mathematics, Basic Mathematics for Data Science, Data Structures and Algorithms,\\nAlgorithms-I/II, Linear Algebra-I/II, Calculus-I/II, Computer Organization & Architecture, Python Programming,\\nPrinciples of Programming Languages, Theory of Computation-I/II, Operations Research, Operating System, Database\\nManagement System, Computer Networks & Security, Compiler Design, Computer System Design, Machine Learning,\\nArtificial Intelligence, Adversarial Machine Learning, Deep Learning for Computer Vision, Natural Language Processing,\\nAI/ML Lab, Advanced Machine Learning(currently doing), Data Analytics and Visualisation(currently doing), Linear\\nProgramming for Computer Science Applications(currently doing)\\nAccomplishments/Additional Information\\n•Smart India Hackathon 2023 Grand Finalist in the Land Profiling problem, the challenge is to create an intricate 3D model\\ncovering various geolocations, land excavations, and landforms.\\n•1st prize in a hackathon IBITF(IIT BHILAI INNOVATION AND TECHNOLOGY FOUNDATION) sponsored by Infineon,\\non the light weight Image clustering problem statement\\n•1st Rank in the project display at RImLand event in VNR Institute. certificate\\n•2nd Rank for website designing of OpenLake community(the open source community of IIT BHILAI).\\n•Top 0.96% rank in Jee-Mains exam.\\n•Recognized as a Microsoft Technology associate for Introduction to Programming in Python. certificate\\nPositions of Responsibility\\n•Core Member ,of Data Science and Artificial Intelligence club of IIT BHILAI 2023-24\\n•Core Member ,of Epsilon Club, the robotics club of IIT BHILAI 2023-24\\n•Facilitator ,of Google Cloud Career Practitioner campaign 2022\\n•Core Member ,of Google Developer Students Club, IIT BHILAI 2022-23\\n•Coordinator ,The Pixel Snappers, photography club of IIT BHILAI check the work here 2023-24\\n•Media Team Head ,Meraz 2024, annual techno-cultural fest of IIT BHILAI 2024\\n•Photography Events Head ,Anveshan 2024, annual cultural’s competition of IIT BHILAI 2024', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({\"text\": resume_text})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc08973a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills:\n",
      "- Python\n",
      "- JavaScript\n",
      "- PyTorch\n",
      "- TensorFlow\n",
      "- ReactJS\n",
      "- Flutter\n",
      "- FastAPI\n",
      "- Ray\n",
      "- Langchain\n",
      "- Crew AI\n",
      "- OpenCV\n",
      "- Pygame\n",
      "- RLLib\n",
      "- Petting Zoo\n",
      "- NNI\n",
      "- grpc\n",
      "- Google Cloud Computing\n",
      "- AWS\n",
      "- Docker\n",
      "- Git\n",
      "- GitHub\n",
      "- SQL\n",
      "- Jupyter\n",
      "- Visual Studio\n",
      "- Figma\n",
      "- Vercel\n",
      "- Machine Learning\n",
      "- Deep Learning\n",
      "- Computer Vision\n",
      "- Natural Language Processing\n",
      "- Reinforcement Learning\n",
      "- Federated Learning\n",
      "- Data Science\n",
      "- Artificial Intelligence\n",
      "- Adversarial Machine Learning\n",
      "- Data Structures & Algorithms\n",
      "- Image Processing\n",
      "- Object Detection\n",
      "- Text Recognition\n",
      "- Multi-modal Alignment\n",
      "- Attention Mechanisms\n",
      "- Camera Calibration\n",
      "- Depth Estimation\n",
      "- Data Analytics\n",
      "- Cloud Computing\n",
      "- Distributed Systems\n",
      "- Model Deployment\n",
      "- Windows\n",
      "- Linux\n",
      "- Android\n",
      "\n",
      "Experience:\n",
      "- Federated Learning Researcher at Edge Lab @ IIT KHARAGPUR (May 2024 - August 2024)\n",
      "- Machine Learning Intern at IBITF @ IIT BHILAI (January 2025 - present)\n",
      "- Split Learning Researcher at S3 Lab (November 2023 - present)\n",
      "- B.Tech Computer Science Engineering at IIT Bhilai (2021 - 2025)\n",
      "- TSBIE(XI-XII) at Narayana Junior College (2019 - 2021)\n",
      "- CBSE(X) at Delhi Public School, Nacharam (2018 - 2018)\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6769354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# system_template2 = \"\"\"\n",
    "# You are an AI assistant that you are proficient in finding, extracting and comparing information from different\n",
    "# texts. You are helping in filtering the cadidate resume by checking how much of a candidate skills\n",
    "# satisfy the requirements. \n",
    "\n",
    "# Given a skills requirement file {skills_file}, {experience_file} where each skill and experience is \n",
    "# mentioned as a bullet point along with a resume file by user. You have to find how many of the skills \n",
    "# mentioned in skills_file and experience in experience_file are fulfilled by the information in resume_file.\n",
    "\n",
    "# 1. Skills — both technical and soft skills.\n",
    "# 2. Experience — summarised job titles, company names, Education Qualification and durations.\n",
    "\n",
    "# Return the output in the following exact format:\n",
    "\n",
    "# Percentage of skills that are fulfilled by the resume:\n",
    "# - Skill 1 (only mention the percentage of satisfying no need to specify the skill name)\n",
    "# - Skill 2 (only mention the percentage of satisfying no need to specify the skill name)\n",
    "# - Skill 3 (only mention the percentage of satisfying no need to specify the skill name)\n",
    "\n",
    "# - Overall Skills satisfying (mention the overall percentage of skills satisfying)\n",
    "\n",
    "# Percentage of experience that are fulfilled by the resume:\n",
    "# - Experience 1 (only mention the percentage of satisfying no need to specify the skill name)\n",
    "# - Experience 2 (only mention the percentage of satisfying no need to specify the skill name)\n",
    "# - Experience 3 (only mention the percentage of satisfying no need to specify the skill name)\n",
    "\n",
    "# - Overall Experience satisfying (mention the overall percentage of experience satisfying)\n",
    "\n",
    "# *Note - if any skill or experience is not fulfilled, mention it as 0%. If for any skill or experience there is\n",
    "# not explicit mentioning in the resume, but it can be inferred from the context, allot some percentage of skill\n",
    "# fulfillment based on the contextual information provided.\n",
    "\n",
    "# Only use the information explicitly stated in the resume_file. Do not infer or fabricate details.\n",
    "# \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f3922aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template2 = \"\"\"\n",
    "You are an AI assistant that you are proficient in finding, extracting and comparing information from different\n",
    "texts. You are helping in filtering the cadidate resume by checking how much of a candidate skills\n",
    "satisfy the requirements. \n",
    "\n",
    "Given a skills requirement file {skills_file}, {experience_file} where each skill and experience is \n",
    "mentioned as a bullet point along with a resume file by user. You have to find how many of the skills \n",
    "mentioned in skills_file and experience in experience_file are fulfilled by the information in resume_file.\n",
    "\n",
    "1. Skills — both technical and soft skills.\n",
    "2. Experience — summarised job titles, company names, Education Qualification and durations.\n",
    "\n",
    "Return the output in the following exact format:\n",
    "\n",
    "- ouput only the overall percentage of skills satisfying and percentage of experience satisfying values\n",
    "seperated by commas. Eg- x,y\n",
    "\n",
    "*Note - if any skill or experience is not fulfilled, mention it as 0%. If for any skill or experience there is\n",
    "not explicit mentioning in the resume, but it can be inferred from the context, allot some percentage of skill\n",
    "fulfillment based on the contextual information provided.\n",
    "\n",
    "Only use the information explicitly stated in the resume_file. Do not infer or fabricate details.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fdbc76af",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template2 = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template2), (\"user\", \"{resume_file}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3760b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../uploads/session-1/skills.txt\", \"r\") as file:\n",
    "    skills_text = file.read()\n",
    "\n",
    "with open(\"../uploads/session-1/experience.txt\", \"r\") as file:\n",
    "    experience_text = file.read()\n",
    "\n",
    "with open(\"../uploads/session-1/RESUME.txt\", \"r\") as file:\n",
    "    resume_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "852a55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = prompt_template2.invoke({\"skills_file\": skills_text, \"experience_file\": experience_text, \"resume_file\": resume_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "57a8b178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40,56\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(prompt2)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5fdff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2f091f9",
   "metadata": {},
   "source": [
    "testing:\n",
    "\n",
    "the fuzzy logic and boolean logic\n",
    "LLM giving different scores for the same document\n",
    "on creating a new session, old session window is shown with session tab changing in the side bar\n",
    "on loading user is not able to go to another session\n",
    "sometimes, LLM output has string and giving NAN as output\n",
    "\n",
    "learn:\n",
    "how whoosh works backend\n",
    "if i use new technique for filtering, how it works\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3a36c6",
   "metadata": {},
   "source": [
    "# Boolean Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be2f97b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.index import create_in\n",
    "from whoosh.fields import Schema, TEXT, ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f313407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema(\n",
    "    id=ID(stored=True, unique=True),  # Unique ID for each document\n",
    "    title=TEXT(stored=True),          # Title field, stored for retrieval\n",
    "    content=TEXT(stored=True)         # Content field, indexed for search\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be50b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"indexdir\"):\n",
    "    os.mkdir(\"indexdir\")\n",
    "ix = create_in(\"indexdir\", schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5abba481",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = ix.writer()\n",
    "docs_fldr = \"../uploads/session-3/PDFS\"\n",
    "\n",
    "for id, file_name in enumerate(os.listdir(docs_fldr)):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        with open(os.path.join(docs_fldr, file_name),'r') as f:\n",
    "            content = f.read()\n",
    "            writer.add_document(id=f\"{id}\", title=file_name, content=content)\n",
    "writer.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06d7dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.qparser import QueryParser\n",
    "from whoosh.query import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34a1c43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits: 11\n",
      "Doc ID: 0, Title: RESUME - Copy - Copy (10).txt, Score: 4.56859161416952\n",
      "Snippet: 2023 - November 2023\n",
      "<b class=\"match term0\">AI</b> Major Project Github...Langchain, Crew <b class=\"match term0\">AI</b>, SQL, ReactJS, Flutter, NNI...Language Processing,\n",
      "<b class=\"match term0\">AI</b>/ML Lab, Advanced Machine\n",
      "-----------------------------------\n",
      "Doc ID: 1, Title: RESUME - Copy - Copy (2).txt, Score: 4.56859161416952\n",
      "Snippet: 2024 - December 2024\n",
      "<b class=\"match term1\">NLP</b> Major Project Github...Virtual-Try-On, <b class=\"match term1\">NLP</b>, Image Processing, Pytorch...Langchain, Crew <b class=\"match term0\">AI</b>, SQL, ReactJS, Flutter, NNI\n",
      "-----------------------------------\n",
      "Doc ID: 2, Title: RESUME - Copy - Copy (3).txt, Score: 4.56859161416952\n",
      "Snippet: 2023 - November 2023\n",
      "<b class=\"match term0\">AI</b> Major Project Github...Langchain, Crew <b class=\"match term0\">AI</b>, SQL, ReactJS, Flutter, NNI...Language Processing,\n",
      "<b class=\"match term0\">AI</b>/ML Lab, Advanced Machine\n",
      "-----------------------------------\n",
      "Doc ID: 3, Title: RESUME - Copy - Copy (4).txt, Score: 4.56859161416952\n",
      "Snippet: Virtual-Try-On, <b class=\"match term1\">NLP</b>, Image Processing, Pytorch...Langchain, Crew <b class=\"match term0\">AI</b>, SQL, ReactJS, Flutter, NNI...Language Processing,\n",
      "<b class=\"match term0\">AI</b>/ML Lab, Advanced Machine\n",
      "-----------------------------------\n",
      "Doc ID: 4, Title: RESUME - Copy - Copy (5).txt, Score: 4.56859161416952\n",
      "Snippet: 2023 - November 2023\n",
      "<b class=\"match term0\">AI</b> Major Project Github...alignment, Attention, <b class=\"match term1\">NLP</b>, CV, Pytorch,\n",
      "numpy•Text...Language Processing,\n",
      "<b class=\"match term0\">AI</b>/ML Lab, Advanced Machine\n",
      "-----------------------------------\n",
      "Doc ID: 5, Title: RESUME - Copy - Copy (6).txt, Score: 4.56859161416952\n",
      "Snippet: 2023 - November 2023\n",
      "<b class=\"match term0\">AI</b> Major Project Github...Langchain, Crew <b class=\"match term0\">AI</b>, SQL, ReactJS, Flutter, NNI...Language Processing,\n",
      "<b class=\"match term0\">AI</b>/ML Lab, Advanced Machine\n",
      "-----------------------------------\n",
      "Doc ID: 6, Title: RESUME - Copy - Copy (7).txt, Score: 4.56859161416952\n",
      "Snippet: 2024 - December 2024\n",
      "<b class=\"match term1\">NLP</b> Major Project Github...Virtual-Try-On, <b class=\"match term1\">NLP</b>, Image Processing, Pytorch...Langchain, Crew <b class=\"match term0\">AI</b>, SQL, ReactJS, Flutter, NNI\n",
      "-----------------------------------\n",
      "Doc ID: 7, Title: RESUME - Copy - Copy (8).txt, Score: 4.56859161416952\n",
      "Snippet: 2024 - December 2024\n",
      "<b class=\"match term1\">NLP</b> Major Project Github...Virtual-Try-On, <b class=\"match term1\">NLP</b>, Image Processing, Pytorch...Langchain, Crew <b class=\"match term0\">AI</b>, SQL, ReactJS, Flutter, NNI\n",
      "-----------------------------------\n",
      "Doc ID: 8, Title: RESUME - Copy - Copy (9).txt, Score: 4.56859161416952\n",
      "Snippet: alignment, Attention, <b class=\"match term1\">NLP</b>, CV, Pytorch,\n",
      "numpy•Text...Virtual-Try-On, <b class=\"match term1\">NLP</b>, Image Processing, Pytorch...Langchain, Crew <b class=\"match term0\">AI</b>, SQL, ReactJS, Flutter, NNI\n",
      "-----------------------------------\n",
      "Doc ID: 9, Title: RESUME - Copy - Copy.txt, Score: 4.56859161416952\n",
      "Snippet: 2023 - November 2023\n",
      "<b class=\"match term0\">AI</b> Major Project Github...2024 - December 2024\n",
      "<b class=\"match term1\">NLP</b> Major Project Github...alignment, Attention, <b class=\"match term1\">NLP</b>, CV, Pytorch,\n",
      "numpy•Text\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Open the searcher\n",
    "with ix.searcher() as searcher:\n",
    "    # Parse a query for the 'content' field\n",
    "    parser = QueryParser(\"content\", ix.schema)\n",
    "    \n",
    "    # Example 1: Simple AND query (implicit)\n",
    "    query = parser.parse(\"ai AND nlp\")\n",
    "    results = searcher.search(query)\n",
    "    print(\"Hits:\", len(results))\n",
    "    for hit in results:\n",
    "        print(f\"Doc ID: {hit['id']}, Title: {hit['title']}, Score: {hit.score}\")\n",
    "        print(\"Snippet:\", hit.highlights(\"content\"))  # Highlights matching terms\n",
    "        print(\"-----------------------------------\")\n",
    "\n",
    "    # Example 2: Boolean OR query\n",
    "    # query = parser.parse(\"apples OR bananas\")\n",
    "    # results = searcher.search(query)\n",
    "    # print(\"\\nOR Query Hits:\", len(results))\n",
    "    # for hit in results:\n",
    "    #     print(f\"Doc ID: {hit['id']}, Title: {hit['title']}\")\n",
    "\n",
    "    # Example 3: NOT query\n",
    "    # query = parser.parse(\"fruit NOT pears\")\n",
    "    # results = searcher.search(query)\n",
    "    # print(\"\\nNOT Query Hits:\", len(results))\n",
    "    # for hit in results:\n",
    "    #     print(f\"Doc ID: {hit['id']}, Title: {hit['title']}\")\n",
    "\n",
    "    # Example 4: Complex boolean with grouping and phrase\n",
    "    # query = parser.parse('(apples OR \"citrus fruits\") AND healthy')\n",
    "    # results = searcher.search(query)\n",
    "    # print(\"\\nComplex Query Hits:\", len(results))\n",
    "    # for hit in results:\n",
    "    #     print(f\"Doc ID: {hit['id']}, Title: {hit['title']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume_filter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
